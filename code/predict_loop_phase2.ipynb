{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from util import *\n",
    "\n",
    "from PIL import ImageFile, Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    \n",
    "## for inceptionresnetv2\n",
    "# from model_zoo.inceptionresnetv2.pytorch_load import inceptionresnetv2\n",
    "\n",
    "# %load_ext autoreloadls\n",
    "\n",
    "# %autoreload 2\n",
    "    \n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.485, 0.456, 0.406]\n",
      "[0.229, 0.224, 0.225]\n"
     ]
    }
   ],
   "source": [
    "## NORMALIZATION\n",
    "\n",
    "cervix_means = [98.629, 91.756, 121.141] # [0.38526953125, 0.358421875, 0.47320703125]\n",
    "cervix_stds = [59.188, 63.595, 57.666] # [0.231203125, 0.24841796875, 0.2252578125]\n",
    "cervix_means = [cervix_means[i]/256 for i in range(len(cervix_means))] \n",
    "cervix_stds = [cervix_stds[i]/256 for i in range(len(cervix_stds))] \n",
    "\n",
    "imagenet_means = [0.485, 0.456, 0.406]\n",
    "imagenet_stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "means = imagenet_means\n",
    "stds = imagenet_stds\n",
    "\n",
    "print(means)\n",
    "print(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TRANSFORMS and PHASES\n",
    "\n",
    "# phases = ['train', 'val', 'test','test_kaggle', 'additional']\n",
    "phases = ['test_stg2_scaled224']\n",
    "# phases = ['test']\n",
    "\n",
    "data_transforms = {\n",
    "    'test_stg2_scaled224': transforms.Compose([\n",
    "            transforms.Scale(224),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means, stds)\n",
    "            ])\n",
    "}\n",
    "\n",
    "for phase in phases:\n",
    "    data_transforms[phase] = data_transforms['test_stg2_scaled224']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DATA LOADER\n",
    "home = os.path.expanduser('~')\n",
    "\n",
    "data_dir = '../../data/test_stg2_all' # alternative validation\n",
    "\n",
    "# exp_str = 'preaug'\n",
    "exp_str = 'phase2_submission_exp1'\n",
    "\n",
    "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "         for x in phases}\n",
    "\n",
    "batch_size = 64\n",
    "dset_loaders = {x: torch.utils.data.DataLoader(\n",
    "                dsets[x], batch_size = batch_size, shuffle=False, num_workers = 16, pin_memory = False)\n",
    "                for x in phases}\n",
    "\n",
    "dset_sizes = {x: len(dsets[x]) for x in phases}\n",
    "# # dset_classes = {x: dsets[x].classes for x in phases}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description  Epoch      loss  \\\n",
      "0  resnet18lr0.00016488533004_wd3.16552084027e-08...     12  0.670640   \n",
      "1  resnet18lr0.000595705150116_wd1.99122445693e-0...     17  0.674302   \n",
      "2  resnet18lr0.000120762743793_wd0.0208152639471_...     22  0.687929   \n",
      "3  resnet34lr0.000385913914401_wd8.70321287782e-0...     16  0.689479   \n",
      "4  resnet34lr0.000155365752892_wd0.00317909033787...      7  0.691991   \n",
      "\n",
      "    model_name           experiment augmentations phase        lr  \\\n",
      "0  resnet18-FT  exp6_stephen_altval         basic   val  0.000165   \n",
      "1  resnet18-FT                 exp3         basic   val  0.000596   \n",
      "2  resnet18-FT          exp-poster2         basic   val  0.000121   \n",
      "3  resnet34-FT         exp5_stephen         basic   val  0.000386   \n",
      "4  resnet34-FT         exp5_stephen         basic   val  0.000155   \n",
      "\n",
      "   weight_decay  pretrained  loss_model  loss_txt  \n",
      "0  3.165521e-08        True    0.670640     0.671  \n",
      "1  1.991224e-06        True    0.674302     0.674  \n",
      "2  2.081526e-02        True    0.687929     0.688  \n",
      "3  8.703213e-05        True    0.689479     0.689  \n",
      "4  3.179090e-03        True    0.691991     0.692  \n"
     ]
    }
   ],
   "source": [
    "## model names\n",
    "# some_squeezenet =  'squeeze11lr0.0072272183267_wd3.05847296262e-06_decayep24_decayconst0.7stamp_1496955129.2932725'\n",
    "# best_res18 = 'resnet18lr0.000120762743793_wd0.0208152639471_decayep11_decayconst0.4stamp_1496392713.9479108'\n",
    "# best_res34 = 'resnet34lr0.000385913914401_wd8.70321287782e-05_decayep12_decayconst0.7stamp_1496458609.4664185'\n",
    "\n",
    "## read names from DF\n",
    "# poster_all = 'best_val_loss_post_poster.csv'\n",
    "# top10 = 'top10_names_all.csv'\n",
    "top5 = 'top5_names_all.csv'\n",
    "# best_in_class =  'select_best_model_name_all.csv'\n",
    "\n",
    "## SETTINGS #################\n",
    "is_ensemble = True\n",
    "# # ensemble_name = 'top10'\n",
    "ensemble_name = 'top5'\n",
    "# # ensemble_name = 'best_in_class'\n",
    "# ####################################\n",
    "\n",
    "# if 'top' in ensemble_name: \n",
    "#     model_list_csv = top5\n",
    "# if ensemble_name == 'best_in_class':\n",
    "#     model_list_csv = best_in_class\n",
    "    \n",
    "model_list_csv = top5\n",
    "df = pd.read_csv('../performance/' + model_list_csv, sep=',',header=0)\n",
    "# df = df.as_matrix()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnet18lr0.00016488533004_wd3.16552084027e-08_decayep12_decayconst0.3stamp_1496692512.7544453', 'resnet18lr0.000595705150116_wd1.99122445693e-06_decayep8_decayconst0.5stamp_1496419169.2827077', 'resnet18lr0.000120762743793_wd0.0208152639471_decayep11_decayconst0.4stamp_1496392713.9479108', 'resnet34lr0.000385913914401_wd8.70321287782e-05_decayep12_decayconst0.7stamp_1496458609.4664185', 'resnet34lr0.000155365752892_wd0.00317909033787_decayep12_decayconst0.6stamp_1496463117.337411']\n"
     ]
    }
   ],
   "source": [
    "num_models = len(df)\n",
    "description_str_list = df['description'].tolist()\n",
    "exp_name_list = df['experiment'].tolist()\n",
    "model_name_list = df['model_name'].tolist()\n",
    "print(description_str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phase1_submission_path = '../../data/solution_stg1_release.csv'\n",
    "phase_1_submission = pd.read_csv(phase1_submission_path, sep=',', header = 0)\n",
    "# print(phase_1_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE:  test_stg2_scaled224\n",
      "0\n",
      "exp6_stephen_altval\n",
      "resnet18-FT\n",
      "MODEL:  exp6_stephen_altval0\n",
      "1\n",
      "exp3\n",
      "resnet18-FT\n",
      "MODEL:  exp31\n",
      "2\n",
      "exp-poster2\n",
      "resnet18-FT\n",
      "MODEL:  exp-poster22\n",
      "3\n",
      "exp5_stephen\n",
      "resnet34-FT\n",
      "MODEL:  exp5_stephen3\n",
      "4\n",
      "exp5_stephen\n",
      "resnet34-FT\n",
      "MODEL:  exp5_stephen4\n"
     ]
    }
   ],
   "source": [
    "## MODELS\n",
    "\n",
    "num_models = len(df)\n",
    "#### SET for topX\n",
    "# num_models = 10\n",
    "######################\n",
    "# exp_name = 'phase_2_submission'\n",
    "# description_str_list = os.listdir('../model_weights/experiments/' + exp_name + '/')\n",
    "\n",
    "for phase in phases:\n",
    "    print('PHASE: ', phase)\n",
    "    for i in range(num_models):\n",
    "        print(i)\n",
    "        ## for top5\n",
    "        description_string = description_str_list[i]\n",
    "        exp_name = exp_name_list[i]\n",
    "        model_name_full = exp_name + str(i)\n",
    "\n",
    "        print(exp_name)\n",
    "        path_checkpoint =  '../model_weights/experiments/' + exp_name + '/' + description_string + '.chkpt'\n",
    "#         model_name = description_string.split('lr')[0]\n",
    "        model_name = model_name_list[i]\n",
    "        print(model_name)\n",
    "\n",
    "        ## ResNet18 ##\n",
    "        if 'resnet18' in model_name:\n",
    "            ## Select Model architecture\n",
    "            model = models.resnet18(pretrained=False)\n",
    "\n",
    "        ## ResNet34 ##\n",
    "        if 'resnet34' in model_name:\n",
    "            ## Select Model architecture\n",
    "            model = models.resnet34(pretrained=False)\n",
    "\n",
    "        if ('resnet18' in model_name) or ('resnet34' in model_name):\n",
    "            ## Replace Classifier\n",
    "            num_ftrs = model.fc.in_features\n",
    "            model.fc = nn.Linear(num_ftrs, 3) \n",
    "\n",
    "        ## reload state\n",
    "        checkpoint = torch.load(path_checkpoint)\n",
    "        sd = {k.replace('module.', '') : v for k, v in checkpoint.items()}\n",
    "        model.load_state_dict(sd)\n",
    "\n",
    "        ## do not train\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False  \n",
    "\n",
    "        ## test if model works\n",
    "        model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "        ## Cuda?\n",
    "        model = model.cuda()\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "\n",
    "        ## PREDICT\n",
    "        print('MODEL: ', model_name_full)\n",
    "\n",
    "        ## loader\n",
    "        dset_loader = dset_loaders[phase]\n",
    "\n",
    "        ## predict\n",
    "        probs, labels = predict_on_test2(model, dset_loader, dtype)\n",
    "\n",
    "        # Extract file name\n",
    "        file_names = dset_loader.dataset.imgs        \n",
    "        file_names = [x[0].split('/')[-1] for x in file_names]\n",
    "        img_names = [x[0:-4] for x in file_names] # remove .jpg\n",
    "        img_names = [x.split('_')[0] for x in img_names] ## remove _descripts\n",
    "        img_names_jpg = [x + '.jpg' for x in img_names]\n",
    "\n",
    "        ## make df\n",
    "        predictions_df = pd.DataFrame(data = probs, columns = (['Type_1', 'Type_2', 'Type_3']))\n",
    "        predictions_df.insert(0, column = 'image_name', value = img_names_jpg)\n",
    "#         predictions_df.insert(4, column = 'labels', value = labels)\n",
    "    #         print(predictions_df)\n",
    "\n",
    "        ## group by image name, take average\n",
    "        grouped_df = predictions_df.groupby('image_name', as_index=False).mean()\n",
    "    #         print(grouped_df)        \n",
    "\n",
    "        ## Save predictions\n",
    "        pred_out_df = grouped_df.copy()\n",
    "#         if phase == 'test_kaggle':\n",
    "#             pred_out_df = pred_out_df.drop('labels', 1)\n",
    "\n",
    "        ## make folders\n",
    "        predictions_dir = '../test_predictions/' + exp_str + '/'\n",
    "        maybe_makedir(predictions_dir)\n",
    "        predictions_dir = predictions_dir + phase + '/'\n",
    "        maybe_makedir(predictions_dir)\n",
    "        ## save\n",
    "        filename = 'scores_' + model_name_full + description_string + '.csv'\n",
    "        pred_out_df.to_csv(path_or_buf = predictions_dir + filename, index = False)\n",
    "\n",
    "        if is_ensemble:\n",
    "            if i==0:\n",
    "                ensemble_scores = grouped_df\n",
    "            else:\n",
    "                ensemble_scores = ensemble_scores.append(grouped_df, ignore_index=True)\n",
    "\n",
    "        ## compute Loss and stats        \n",
    "        if phase == 'test':\n",
    "            preds_labels = grouped_df.as_matrix()\n",
    "            probs = preds_labels[:, 1:4].astype(np.float)\n",
    "            labels = preds_labels[:, 4].astype(np.int)\n",
    "\n",
    "            ## collect the stats and loss\n",
    "            df_stats = stats_from_probs(probs, labels, description_string, phase)\n",
    "            df_stats['model_name_full'] = model_name_full \n",
    "    #             print(df_stats)\n",
    "\n",
    "            ## save\n",
    "            filename = 'test_stats_' + model_name_full +description_string + '.csv'\n",
    "            df_stats.to_csv(path_or_buf = predictions_dir + filename, index = False)\n",
    "\n",
    "            if is_ensemble:\n",
    "                if i==0:\n",
    "                    ensemble_stats = df_stats\n",
    "                else:\n",
    "                    ensemble_stats = ensemble_stats.append(df_stats, ignore_index=True)\n",
    "\n",
    "\n",
    "    \n",
    "    if is_ensemble: #and any(\"test\" == p for p in phases)\n",
    "        print('-'*10  + 'Computing Ensemble' + '-'*10 )\n",
    "        ## make folders\n",
    "        predictions_dir = '../test_predictions/' + exp_str + '/'\n",
    "        maybe_makedir(predictions_dir)\n",
    "        predictions_dir = predictions_dir + phase + '/'\n",
    "        maybe_makedir(predictions_dir)\n",
    "\n",
    "        ## save individual scores\n",
    "        filename = 'scores_ensemble_individual_' +ensemble_name+ '.csv'\n",
    "        ensemble_scores.to_csv(path_or_buf = predictions_dir + filename, index = False)\n",
    "        \n",
    "        ## save stats\n",
    "        if phase == 'test':\n",
    "            filename = 'test_stats_ensemble_individual_' +ensemble_name+ '.csv'\n",
    "            ensemble_stats.to_csv(path_or_buf = predictions_dir + filename, index = False)\n",
    "\n",
    "        # average scores\n",
    "        ensemble_scores_grouped = ensemble_scores.groupby('image_name', as_index=False).mean()\n",
    "        ensemble_scores_out = ensemble_scores_grouped.copy()\n",
    "        \n",
    "        # Append the phase 1 scores\n",
    "        \n",
    "#         if phase == 'test_kaggle':\n",
    "#             ensemble_scores_out = ensemble_scores_out.drop('labels', 1) \n",
    "        ensemble_scores_out = ensemble_scores_out.append(phase_1_submission, ignore_index = True)\n",
    "    \n",
    "        ## save average scores\n",
    "        filename = 'scores_ensemble_mean_' + ensemble_name + '.csv'\n",
    "        ensemble_scores_out.to_csv(path_or_buf = predictions_dir + filename, index = False)\n",
    "\n",
    "        ## collect the stats and loss\n",
    "        if phase == 'test':\n",
    "            preds_labels = ensemble_scores_grouped.as_matrix()\n",
    "            probs = preds_labels[:, 1:4].astype(np.float)\n",
    "            labels = preds_labels[:, 4].astype(np.int)\n",
    "\n",
    "            df_stats = stats_from_probs(probs, labels, ensemble_name, 'test')\n",
    "            df_stats['model_name_full'] = ensemble_name \n",
    "        #   print(df_stats)\n",
    "\n",
    "            ## save collected stats\n",
    "            filename = 'test_stats_ensemble_mean_' +ensemble_name+ '.csv'\n",
    "            df_stats.to_csv(path_or_buf = predictions_dir + filename, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
